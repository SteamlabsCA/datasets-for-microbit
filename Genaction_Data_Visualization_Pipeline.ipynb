{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "laU6H3CYNdPU"
      },
      "source": [
        "# Genaction: Data Visualization Pipeline\n",
        "This is a playground pipeline that collects from multiple data sources. Not all code is final. To see the final code, feel free to take a look at [this repo](https://github.com/SteamlabsCA/data-visualization)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "69_IxugJepxY"
      },
      "source": [
        "# Installing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tkDWcJyZxcW",
        "outputId": "adeec049-7a3e-4f5a-d8b2-d81ec2d76f36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xlsxwriter in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (3.1.2)\n",
            "Requirement already satisfied: pandas in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (2.0.2)\n",
            "Requirement already satisfied: xarray in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (2023.1.0)\n",
            "Requirement already satisfied: bs4 in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (0.0.1)\n",
            "Requirement already satisfied: requests in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (2.31.0)\n",
            "Requirement already satisfied: lxml in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (4.9.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (from pandas) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (from xarray) (23.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (from bs4) (4.12.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (from requests) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (from requests) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (from requests) (2023.5.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (from requests) (2.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install xlsxwriter pandas xarray bs4 requests lxml"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f8bqvpSmNvzR"
      },
      "source": [
        "# Importing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l7lIfRrANyGJ"
      },
      "outputs": [],
      "source": [
        "from datetime import date, datetime\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests as r\n",
        "from bs4 import BeautifulSoup\n",
        "import xarray as xr\n",
        "import os\n",
        "\n",
        "import glob\n",
        "import shutil\n",
        "import pathlib"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b3Dc9HKXpC-V"
      },
      "source": [
        "# Configuring Settings"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IBrYK2sOBKhN"
      },
      "source": [
        "## Setting Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EukW7rTmpGu7",
        "outputId": "4a4ea8b5-ec77-4fd2-bca3-24a49623715b"
      },
      "outputs": [],
      "source": [
        "path = 'data'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nX68MxZjBLym"
      },
      "source": [
        "## Pandas Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JKJcctNBBN9G"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M9NX8QbEL2JF"
      },
      "source": [
        "# Hourly Fuel Output"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ooVlkd7_MftJ"
      },
      "source": [
        "## Downloading Data Utilities"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XwdvmB1_MftP"
      },
      "source": [
        "### Extract Ontario Fuel Output\n",
        "At the moment, I'm aggregating historical energy output in Ontario. The data is split into two parts.\n",
        "\n",
        "1. `PUB_GenOutputbyFuelHourly.xml`: Hourly energy usage output from\n",
        "the previous 12 months.\n",
        "\n",
        "2. `PUB_GenOutputbyFuelHourly_XXXX.xml`: Hourly energy usage output\n",
        "from year XXXX.\n",
        "\n",
        "However, the format of the dataset is consistent. It's as follows:\n",
        "\n",
        "```xml\n",
        "<DocBody>\n",
        "    <DeliveryYear>2022</DeliveryYear>\n",
        "    <DailyData>\n",
        "        <Day>2022-01-01</Day>\n",
        "        <HourlyData>\n",
        "            <Hour>1</Hour>\n",
        "\n",
        "            <FuelTotal>\n",
        "                <Fuel>NUCLEAR</Fuel>\n",
        "                <EnergyValue>\n",
        "                    <OutputQuality>0</OutputQuality>\n",
        "                    <Output>10474</Output>\n",
        "                </EnergyValue>\n",
        "            </FuelTotal>\n",
        "            [...]\n",
        "\n",
        "        </HourlyData>\n",
        "        [...]\n",
        "    </DailyData>\n",
        "    [...]\n",
        "</DocBody>\n",
        "```\n",
        "\n",
        "Note that `[...]` implies repeated elements.\n",
        "\n",
        "Collecting the data is a matter of traversing the tree and collecting\n",
        "the needed information.\n",
        "\n",
        "One issue I've run into is that BeautifulSoup takes a few seconds to\n",
        "parse the needed XML. However, I will ignore this as it doesn't cause\n",
        "significant problems.\n",
        "\n",
        "In the situation where this may cause issues later, I would switch to\n",
        "an XML parsing library such as `lxml`."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RQJQeEI-MftP"
      },
      "source": [
        "## Transforming Data Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ltnwEGKgMftQ"
      },
      "outputs": [],
      "source": [
        "def _extract_fuel_output(url):\n",
        "  xml = r.get(url).content\n",
        "\n",
        "  soup = BeautifulSoup(xml, \"xml\")\n",
        "\n",
        "  year = soup.find(\"DeliveryYear\").text\n",
        "\n",
        "  daily_data = soup.find_all(\"DailyData\")\n",
        "\n",
        "  for day_data in daily_data:\n",
        "    date = day_data.find(\"Day\")\n",
        "    if date:\n",
        "      date_obj = datetime.strptime(date.text, '%Y-%m-%d')\n",
        "\n",
        "      month = date_obj.month\n",
        "      day = date_obj.day\n",
        "\n",
        "    hourly_datas = day_data.find_all(\"HourlyData\")\n",
        "\n",
        "    for hourly_data in hourly_datas:\n",
        "      hour = hourly_data.find(\"Hour\")\n",
        "      if hour:\n",
        "        hour = int(hour.text)\n",
        "\n",
        "      fuel_totals = hourly_data.find_all(\"FuelTotal\")\n",
        "\n",
        "      for fuel_total in fuel_totals:\n",
        "        fuel = fuel_total.find(\"Fuel\")\n",
        "        if fuel:\n",
        "          fuel = fuel.text\n",
        "\n",
        "        output = fuel_total.find(\"Output\")\n",
        "        if output:\n",
        "          output = int(output.text)\n",
        "\n",
        "        yield {\n",
        "          \"year\": year,\n",
        "          \"month\": month,\n",
        "          \"day\": day,\n",
        "          \"hour\": hour,\n",
        "          \"fuel\": fuel,\n",
        "          \"output\": output\n",
        "        }"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dr9LH_BeMftQ"
      },
      "source": [
        "### Get Provincial/National Fuel Output Percentages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "e_CqvolSMftQ"
      },
      "outputs": [],
      "source": [
        "def _collect_fuel_output_percentage(YEAR_TO_COLLECT):\n",
        "  fuel_output_percentages = []\n",
        "\n",
        "  regions = pd \\\n",
        "    .read_csv(\"https://www.cer-rec.gc.ca/open/energy/energyfutures2021/electricity-generation-2021.csv\") \\\n",
        "    .query(f\"Year == {YEAR_TO_COLLECT}\") \\\n",
        "    .query(f\"Scenario == 'Current Policies'\") \\\n",
        "    .drop([\"Scenario\", \"Type\", \"Type\", \"Unit\"], axis=1) \\\n",
        "    .groupby(\"Region\")\n",
        "\n",
        "  for region_name, region_df in regions:\n",
        "    total_output = region_df[\"Value\"].sum().round(2)\n",
        "\n",
        "    baseload_output = region_df.query(\"Variable in ('NUCLEAR', 'HYDRO', 'BIOFUEL')\")[\"Value\"].sum()\n",
        "    solar_output = region_df.query(\"Variable == 'Solar'\").iloc[0][\"Value\"]\n",
        "    wind_output = region_df.query(\"Variable == 'Wind'\").iloc[0][\"Value\"]\n",
        "\n",
        "    baseload_percent = baseload_output / total_output\n",
        "    solar_percent = solar_output / total_output\n",
        "    wind_percent = wind_output / total_output\n",
        "\n",
        "    fuel_output_percentages.append({\n",
        "      \"region_name\": region_name,\n",
        "      \"baseload_percent\": baseload_percent,\n",
        "      \"solar_percent\": solar_percent,\n",
        "      \"wind_percent\": wind_percent\n",
        "    })\n",
        "\n",
        "    return fuel_output_percentages"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ISar0h0hMftQ"
      },
      "source": [
        "### Scaling Ontario Fuel Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "52Rm_-VLMftQ"
      },
      "outputs": [],
      "source": [
        "def _transform_ontario_fuel_output(\n",
        "    fuel_output_df,\n",
        "    provincial_baseload_percent,\n",
        "    provincial_solar_percent,\n",
        "    provincial_wind_percent\n",
        "  ):\n",
        "  \"\"\"Step 0 - Setting Needed Values\"\"\"\n",
        "  # 24 hour clock\n",
        "  # See Step 1.1 for application.\n",
        "  time_blocks = [\n",
        "      (7, 8, 9),\n",
        "      (11, 12, 13),\n",
        "      (15, 16, 17, 18, 19),\n",
        "      (21, 22, 23, 24, 1),\n",
        "      (3, 4, 5)\n",
        "  ]\n",
        "\n",
        "  \"\"\"Step 1 - Basic Preprocessing\"\"\"\n",
        "  \"\"\"\n",
        "  Step 1.1 - Apply the following transformations to the fuel output\n",
        "    * 1.1.1\n",
        "    * 1.1.2. Group by fuel type\n",
        "    * 1.1.3. Group by month\n",
        "    * 1.1.4. Group by time blocks (see constants)\n",
        "    * 1.1.5. Calculate the mean of every time block\n",
        "\n",
        "  It should possible for a user to get an item from the final DataFrame\n",
        "  by the fuel type, month and time.\n",
        "\n",
        "  For example, a user can get solar energy output from January at 1am\n",
        "  \"\"\"\n",
        "\n",
        "  data = []\n",
        "\n",
        "  grouped_by_year = fuel_output_df.groupby(\"year\") # 1.1.1\n",
        "\n",
        "  for _, date_df in grouped_by_year:\n",
        "\n",
        "    grouped_by_fuel_type = date_df.groupby(\"fuel\") # 1.1.2\n",
        "\n",
        "    for _, fuel_type_df in grouped_by_fuel_type:\n",
        "      grouped_by_month = fuel_type_df.groupby(\"month\") # 1.1.3\n",
        "\n",
        "      for _, month_df in grouped_by_month:\n",
        "\n",
        "        for time_block in time_blocks:\n",
        "          grouped_by_time_block = month_df[month_df[\"hour\"].isin(time_block)] # 1.1.4\n",
        "\n",
        "          year = grouped_by_time_block[\"year\"].iloc[0]\n",
        "          month = grouped_by_time_block[\"month\"].iloc[0]\n",
        "          start_hour = time_block[0]\n",
        "          end_hour = time_block[-1]\n",
        "          fuel = grouped_by_time_block[\"fuel\"].iloc[0]\n",
        "          output = grouped_by_time_block[\"output\"].mean().round(2) # 1.1.5\n",
        "\n",
        "          data.append(\n",
        "            {\n",
        "                \"year\": year,\n",
        "                \"month\": month,\n",
        "                \"start_hour\": start_hour,\n",
        "                \"end_hour\": end_hour,\n",
        "                \"fuel\": fuel,\n",
        "                \"output\": output\n",
        "            }\n",
        "          )\n",
        "\n",
        "  fuel_output_df = pd.DataFrame(data)\n",
        "\n",
        "  \"\"\"Step 1.2 - Getting arrays of the power generation values\"\"\"\n",
        "  gas = fuel_output_df[fuel_output_df[\"fuel\"] == \"GAS\"] \\\n",
        "    .reset_index() \\\n",
        "    .drop([\"index\"], axis=1)\n",
        "\n",
        "  wind = fuel_output_df[fuel_output_df[\"fuel\"] == \"WIND\"] \\\n",
        "    .reset_index() \\\n",
        "    .drop([\"index\"], axis=1)\n",
        "\n",
        "  solar = fuel_output_df[fuel_output_df[\"fuel\"] == \"SOLAR\"] \\\n",
        "    .reset_index() \\\n",
        "    .drop([\"index\"], axis=1)\n",
        "\n",
        "  # Baseload Fuels\n",
        "  nuclear = fuel_output_df[fuel_output_df[\"fuel\"] == \"NUCLEAR\"] \\\n",
        "    .reset_index() \\\n",
        "    .drop([\"index\"], axis=1)\n",
        "\n",
        "  hydro = fuel_output_df[fuel_output_df[\"fuel\"] == \"HYDRO\"] \\\n",
        "    .reset_index() \\\n",
        "    .drop([\"index\"], axis=1)\n",
        "\n",
        "  biofuel = fuel_output_df[fuel_output_df[\"fuel\"] == \"BIOFUEL\"] \\\n",
        "    .reset_index() \\\n",
        "    .drop([\"index\"], axis=1)\n",
        "\n",
        "  \"\"\"Step 1.3 - Getting the total power array\"\"\"\n",
        "  total_energy_generated = gas[\"output\"] + wind[\"output\"] + solar[\"output\"] + nuclear[\"output\"] + hydro[\"output\"] + biofuel[\"output\"]\n",
        "\n",
        "  \"\"\"Step 2 - Getting Scaling Factors\"\"\"\n",
        "  \"\"\"Step 2.1 - Getting the percent ratio between Alberta's baseload percent and Ontario's baseload percent\"\"\"\n",
        "  ONTARIO_BASELOAD_PERCENT = 0.83\n",
        "  baseload_percent_ratio = provincial_baseload_percent/ONTARIO_BASELOAD_PERCENT\n",
        "\n",
        "  \"\"\"Step 2.2 - Getting the percent ratio between Alberta's solar percent and Ontario's solar percent\"\"\"\n",
        "  ONTARIO_SOLAR_PERCENT = 0.01\n",
        "  solar_percent_ratio = provincial_solar_percent/ONTARIO_SOLAR_PERCENT\n",
        "\n",
        "  \"\"\"Step 2.3 - Getting the percent ratio between Alberta's wind percent and Ontario's wind percent\"\"\"\n",
        "  ONTARIO_WIND_PERCENT = 0.08\n",
        "  wind_percent_ratio = provincial_wind_percent/ONTARIO_WIND_PERCENT\n",
        "\n",
        "  \"\"\"Step 3 - Scaling the Power\"\"\"\n",
        "  \"\"\"Step 3.1 - Multiply each item in the solar power array by the solar percent ratio\"\"\"\n",
        "  solar[\"output_scaled\"] = solar[\"output\"] * solar_percent_ratio\n",
        "\n",
        "  \"\"\"Step 3.2 - Multiply each item in the wind power array by the wind percent ratio\"\"\"\n",
        "  wind[\"output_scaled\"] = wind[\"output\"] * wind_percent_ratio\n",
        "\n",
        "  \"\"\"Step 3.3 - Multiply each item in the baseload power array by the baseload percent ratio\"\"\"\n",
        "  nuclear[\"output_scaled\"] = nuclear[\"output\"] * baseload_percent_ratio\n",
        "  hydro[\"output_scaled\"] = hydro[\"output\"] * baseload_percent_ratio\n",
        "  biofuel[\"output_scaled\"] = biofuel[\"output\"] * baseload_percent_ratio\n",
        "  gas[\"output_scaled\"] = gas[\"output\"] * baseload_percent_ratio\n",
        "\n",
        "  \"\"\"Step 3.4 - Add each item from the scaled solar, scaled wind, and scaled baseload arrays\"\"\"\n",
        "  total_energy_generated_scaled = solar[\"output_scaled\"] + wind[\"output_scaled\"] + nuclear[\"output_scaled\"] + hydro[\"output_scaled\"] + biofuel[\"output_scaled\"] + gas[\"output_scaled\"]\n",
        "\n",
        "  \"\"\"Step 3.5 - Subtract the above value from each item in the total list\"\"\"\n",
        "  fossil_fuels_scaled = total_energy_generated - total_energy_generated_scaled\n",
        "  fossil_fuels_scaled = fossil_fuels_scaled.round(2)\n",
        "\n",
        "  \"\"\"Step 4 - Power Array Percentages\"\"\"\n",
        "  \"\"\"Step 4.1 - Divide each of the scaled arrays by the total list\"\"\"\n",
        "  # Note, in Linear Algebra, it involves taking the inverse of the total list and\n",
        "  # multiplying it by every scaled array.\n",
        "  solar[\"power_percentage\"] = solar[\"output_scaled\"] / total_energy_generated_scaled\n",
        "  wind[\"power_percentage\"] = wind[\"output_scaled\"] / total_energy_generated_scaled\n",
        "  nuclear[\"power_percentage\"] = nuclear[\"output_scaled\"] / total_energy_generated_scaled\n",
        "  hydro[\"power_percentage\"] = hydro[\"output_scaled\"] / total_energy_generated_scaled\n",
        "  biofuel[\"power_percentage\"] = biofuel[\"output_scaled\"] / total_energy_generated_scaled\n",
        "  gas[\"power_percentage\"] = gas[\"output_scaled\"] / total_energy_generated_scaled\n",
        "\n",
        "  \"\"\"Step 4.2 - Multiply by 100 to get total power percentage\"\"\"\n",
        "  # Note that some outputs are so absurdly small that you'd spend 30 minutes trying\n",
        "  # to multiply by 10,000 thinking that Pandas is weird when in reality... they're\n",
        "  # just REALLY small.\n",
        "  solar[\"power_percentage\"] *= 100\n",
        "  wind[\"power_percentage\"] *= 100\n",
        "  nuclear[\"power_percentage\"] *= 100\n",
        "  hydro[\"power_percentage\"] *= 100\n",
        "  biofuel[\"power_percentage\"] *= 100\n",
        "  gas[\"power_percentage\"] *= 100\n",
        "\n",
        "  \"\"\"Step 5 - Final Clean\"\"\"\n",
        "  \"\"\"Step 5.1 - Round values over 100\"\"\"\n",
        "  solar[solar[\"power_percentage\"] > 100] = 100\n",
        "  wind[wind[\"power_percentage\"] > 100] = 100\n",
        "  nuclear[nuclear[\"power_percentage\"] < 0] = 0\n",
        "  hydro[hydro[\"power_percentage\"] < 0] = 0\n",
        "  biofuel[biofuel[\"power_percentage\"] < 0] = 0\n",
        "  gas[gas[\"power_percentage\"] < 0] = 0\n",
        "\n",
        "  \"\"\"Step 5.2 - Round values under 0\"\"\"\n",
        "  solar[solar[\"power_percentage\"] > 100] = 100\n",
        "  wind[wind[\"power_percentage\"] > 100] = 100\n",
        "  nuclear[nuclear[\"power_percentage\"] < 0] = 0\n",
        "  hydro[hydro[\"power_percentage\"] < 0] = 0\n",
        "  biofuel[biofuel[\"power_percentage\"] < 0] = 0\n",
        "  gas[gas[\"power_percentage\"] < 0] = 0\n",
        "\n",
        "  return solar, wind, nuclear, hydro, biofuel, gas, fossil_fuels_scaled"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pW7etCoIMvVR"
      },
      "source": [
        "## IESO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7o39hX9ZM3w2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/t/code/steamlabs-2023/gen-content/venv/lib/python3.8/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'text'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[28], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m   total_fuel_output\u001b[39m.\u001b[39mto_csv(csv_path)\n\u001b[1;32m     45\u001b[0m   total_fuel_output\u001b[39m.\u001b[39mto_excel(xlsx_path)\n\u001b[0;32m---> 47\u001b[0m _load_hourly_fuel_output()\n",
            "Cell \u001b[0;32mIn[28], line 39\u001b[0m, in \u001b[0;36m_load_hourly_fuel_output\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_hourly_fuel_output\u001b[39m():\n\u001b[0;32m---> 39\u001b[0m   total_fuel_output \u001b[39m=\u001b[39m _transform_hourly_fuel_output()\n\u001b[1;32m     41\u001b[0m   csv_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m/hourly_fuel_output/Hourly Fuel Output Ontario - IESO.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m   xlsx_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m/hourly_fuel_output/Hourly Fuel Output Ontario - IESO.xlsx\u001b[39m\u001b[39m\"\u001b[39m\n",
            "Cell \u001b[0;32mIn[28], line 9\u001b[0m, in \u001b[0;36m_transform_hourly_fuel_output\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform_hourly_fuel_output\u001b[39m():\n\u001b[0;32m----> 9\u001b[0m   hourly_fuel_output \u001b[39m=\u001b[39m _extract_hourly_fuel_output()\n\u001b[1;32m     10\u001b[0m   hourly_fuel_output_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(hourly_fuel_output)\n\u001b[1;32m     12\u001b[0m   solar, wind, nuclear, hydro, biofuel, gas, fossil_fuels_scaled \u001b[39m=\u001b[39m _transform_ontario_fuel_output(hourly_fuel_output_df, \u001b[39m0.0\u001b[39m, \u001b[39m0.005\u001b[39m, \u001b[39m0.06\u001b[39m)\n",
            "Cell \u001b[0;32mIn[28], line 4\u001b[0m, in \u001b[0;36m_extract_hourly_fuel_output\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Extracts hourly fuel output data'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m fuel_output_hourly_url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttp://reports.ieso.ca/public/GenOutputbyFuelHourly/PUB_GenOutputbyFuelHourly.xml\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fuel_output_hourly \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(_extract_fuel_output(fuel_output_hourly_url))\n\u001b[1;32m      6\u001b[0m \u001b[39mreturn\u001b[39;00m fuel_output_hourly\n",
            "Cell \u001b[0;32mIn[26], line 6\u001b[0m, in \u001b[0;36m_extract_fuel_output\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      2\u001b[0m xml \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mget(url)\u001b[39m.\u001b[39mcontent\n\u001b[1;32m      4\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(xml, \u001b[39m\"\u001b[39m\u001b[39mlxml\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m year \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39;49mfind(\u001b[39m\"\u001b[39;49m\u001b[39mDeliveryYear\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mtext\n\u001b[1;32m      8\u001b[0m daily_data \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind_all(\u001b[39m\"\u001b[39m\u001b[39mDailyData\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m day_data \u001b[39min\u001b[39;00m daily_data:\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
          ]
        }
      ],
      "source": [
        "def _extract_hourly_fuel_output():\n",
        "  '''Extracts hourly fuel output data'''\n",
        "  fuel_output_hourly_url = \"http://reports.ieso.ca/public/GenOutputbyFuelHourly/PUB_GenOutputbyFuelHourly.xml\"\n",
        "  fuel_output_hourly = list(_extract_fuel_output(fuel_output_hourly_url))\n",
        "\n",
        "  return fuel_output_hourly\n",
        "\n",
        "def _transform_hourly_fuel_output():\n",
        "  hourly_fuel_output = _extract_hourly_fuel_output()\n",
        "  hourly_fuel_output_df = pd.DataFrame(hourly_fuel_output)\n",
        "\n",
        "  solar, wind, nuclear, hydro, biofuel, gas, fossil_fuels_scaled = _transform_ontario_fuel_output(hourly_fuel_output_df, 0.0, 0.005, 0.06)\n",
        "\n",
        "  total_fuel_output = pd.concat(\n",
        "    {\n",
        "      \"Year\": solar[\"year\"],\n",
        "      \"Month\": solar[\"month\"],\n",
        "      \"Start Hour\": solar[\"start_hour\"],\n",
        "      \"End Hour\": solar[\"end_hour\"],\n",
        "      \"Solar Output\": solar[\"output\"],\n",
        "      \"Wind Output\": wind[\"output\"],\n",
        "      \"Nuclear Output\": nuclear[\"output\"],\n",
        "      \"Hydro Output\": hydro[\"output\"],\n",
        "      \"Biofuel Output\": biofuel[\"output\"],\n",
        "      \"Gas Output\": gas[\"output\"],\n",
        "      \"Fossil Fuels Scaled\": fossil_fuels_scaled\n",
        "    },\n",
        "    axis=1\n",
        "  )\n",
        "\n",
        "  total_fuel_output[\"Total Output\"] = total_fuel_output \\\n",
        "    [[\"Solar Output\", \"Wind Output\", \"Nuclear Output\", \"Hydro Output\", \"Biofuel Output\", \"Gas Output\", \"Fossil Fuels Scaled\"]] \\\n",
        "    .sum(axis=1) \\\n",
        "    .round(2)\n",
        "\n",
        "  return total_fuel_output\n",
        "\n",
        "def _load_hourly_fuel_output():\n",
        "  total_fuel_output = _transform_hourly_fuel_output()\n",
        "\n",
        "  csv_path = f\"{path}/hourly_fuel_output/Hourly Fuel Output Ontario - IESO.csv\"\n",
        "  xlsx_path = f\"{path}/hourly_fuel_output/Hourly Fuel Output Ontario - IESO.xlsx\"\n",
        "\n",
        "  total_fuel_output.to_csv(csv_path)\n",
        "  total_fuel_output.to_excel(xlsx_path)\n",
        "\n",
        "_load_hourly_fuel_output()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dkO84B1oPKhK"
      },
      "source": [
        "# Mean Temperature"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "P2K5adY1AtHJ"
      },
      "source": [
        "## Downloading Data Utilities"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0fhXlnq-JAit"
      },
      "source": [
        "### Climate Atlas Of Canada\n",
        "\n",
        "I'm not proud of this method... however, I find it as an easier temporary solution...\n",
        "\n",
        "Rather then download and query data from the PCIC, I will directly download data from the Climate Atlas of Canada.\n",
        "\n",
        "I don't like doing this. However, given the time constraints, I certaintly need to get this done ASAP.\n",
        "\n",
        "A major TODO is to use PCIC data to collect the following data. I don't think it's right to scrape data that someone else preprocessed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X07ADboNJqoA"
      },
      "outputs": [],
      "source": [
        "def _download_climate_atlas_data(city_num: int, variable: str):\n",
        "  possible_values = {\"precip\", \"meantemp\"}\n",
        "  if not variable in possible_values:\n",
        "    raise ValueError(f\"Invalid `variable` value. Should be in {possible_values}\")\n",
        "  \n",
        "  url = f\"https://data.climateatlas.ca/csv/city_{city_num}/BCCAQv2/85/city_{city_num}_BCCAQv2_RCP85_annual_{variable}_ensemble.csv\"\n",
        "\n",
        "  if r.get(url).status_code == 404:\n",
        "    raise ValueError(\"Invalid `city_num` value.\")\n",
        "\n",
        "  # The first 7 lines of any Climate Atlas Data Sheet looks\n",
        "  # like the following (for example)\n",
        "  #\n",
        "  # 1 | Bias  correction  method:  BCCAQv2\n",
        "  # 2 | Model  name:  Ensemble\n",
        "  # 3 | RCP:  85\n",
        "  # 4 | Variable:  tasmax  and  tasmin\n",
        "  # 5 | Season:  annual\n",
        "  # 6 | 1950-01-01  to  2095-12-31\n",
        "  # 7 | city_445:  Average  value  Mean  Ensemble\n",
        "  #\n",
        "  # I will skip these lines in order to get the needed\n",
        "  # data\n",
        "  return pd.read_csv(url, skiprows=7)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IYouaKWgWs-N"
      },
      "source": [
        "## Climate Atlas Of Canada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj5Nd8wzW3nt"
      },
      "outputs": [],
      "source": [
        "# TODO: Specify the ID as a part of the data from the Climate Atlas of Canada.\n",
        "# the rough part would be tediously renaming everything. But alas, it would\n",
        "# clarify the distinction between the various data sources.\n",
        "cities = [\n",
        "  { \"City Name\": \"Timmins\", \"Province Name\": \"Ontario\", \"ID\": \"430\" },\n",
        "  { \"City Name\": \"Ottawa\", \"Province Name\": \"Ontario\", \"ID\": \"459\" },\n",
        "  { \"City Name\": \"Toronto\", \"Province Name\": \"Ontario\", \"ID\": \"458\" },\n",
        "  { \"City Name\": \"Thunder Bay\", \"Province Name\": \"Ontario\", \"ID\": \"444\" },\n",
        "  { \"City Name\": \"Regina\", \"Province Name\": \"Saskatchewan\", \"ID\": \"457\" },\n",
        "  { \"City Name\": \"Saskatoon\", \"Province Name\": \"Saskatchewan\", \"ID\": \"445\" },\n",
        "  { \"City Name\": \"Thompson\", \"Province Name\": \"Manitoba\", \"ID\": \"343\" },\n",
        "  { \"City Name\": \"Brandon\", \"Province Name\": \"Manitoba\", \"ID\": \"430\" },\n",
        "  { \"City Name\": \"Winnipeg\", \"Province Name\": \"Manitoba\", \"ID\": \"465\" },\n",
        "  { \"City Name\": \"Prince George\", \"Province Name\": \"British Columbia\", \"ID\": \"443\" },\n",
        "  { \"City Name\": \"Kelowna\", \"Province Name\": \"British Columbia\", \"ID\": \"442\" },\n",
        "  { \"City Name\": \"Vancouver\", \"Province Name\": \"British Columbia\", \"ID\": \"455\" },\n",
        "  { \"City Name\": \"Grande Prairie\", \"Province Name\": \"Alberta\", \"ID\": \"436\" },\n",
        "  { \"City Name\": \"Edmonton\", \"Province Name\": \"Alberta\", \"ID\": \"466\" },\n",
        "  { \"City Name\": \"Fort McMurray\", \"Province Name\": \"Alberta\", \"ID\": \"437\" },\n",
        "  { \"City Name\": \"Calgary\", \"Province Name\": \"Alberta\", \"ID\": \"454\" },\n",
        "  { \"City Name\": \"Edmundston\", \"Province Name\": \"New Brunswick\", \"ID\": \"273\" },\n",
        "  { \"City Name\": \"Bathurst\", \"Province Name\": \"New Brunswick\", \"ID\": \"274\" },\n",
        "  { \"City Name\": \"Frecdricton\", \"Province Name\": \"New Brunswick\", \"ID\": \"461\" },\n",
        "  { \"City Name\": \"Moncton\", \"Province Name\": \"New Brunswick\", \"ID\": \"394\" },\n",
        "  { \"City Name\": \"Saint John\", \"Province Name\": \"New Brunswick\", \"ID\": \"393\" },\n",
        "  { \"City Name\": \"Labrador City\", \"Province Name\": \"NewfoundLand\", \"ID\": \"260\" },\n",
        "  { \"City Name\": \"Cornoerbrook\", \"Province Name\": \"NewfoundLand\", \"ID\": \"493\" },\n",
        "  { \"City Name\": \"St John\", \"Province Name\": \"NewfoundLand\", \"ID\": \"464\" },\n",
        "  { \"City Name\": \"Cambridge Bay\", \"Province Name\": \"Nunavut\", \"ID\": \"254\" },\n",
        "  { \"City Name\": \"Arviat\", \"Province Name\": \"Nunavut\", \"ID\": \"248\" },\n",
        "  { \"City Name\": \"Iqaluit\", \"Province Name\": \"Nunavut\", \"ID\": \"246\" },\n",
        "  { \"City Name\": \"Dawson\", \"Province Name\": \"Yukon\", \"ID\": \"58\" },\n",
        "  { \"City Name\": \"Whitehorse\", \"Province Name\": \"Yukon\", \"ID\": \"467\" },\n",
        "  { \"City Name\": \"Sept-iles\", \"Province Name\": \"Quebec\", \"ID\": \"303\" },\n",
        "  { \"City Name\": \"Val-d'Or\", \"Province Name\": \"Quebec\", \"ID\": \"297\" },\n",
        "  { \"City Name\": \"Inukjuak\", \"Province Name\": \"Quebec\", \"ID\": \"145\" },\n",
        "  { \"City Name\": \"Montreal\", \"Province Name\": \"Quebec\", \"ID\": \"450\" },\n",
        "  { \"City Name\": \"Quebec\", \"Province Name\": \"Quebec\", \"ID\": \"460\" },\n",
        "  { \"City Name\": \"Summerside\", \"Province Name\": \"PEI\", \"ID\": \"262\" },\n",
        "  { \"City Name\": \"Charlottetown\", \"Province Name\": \"PEI\", \"ID\": \"462\" },\n",
        "  { \"City Name\": \"Truro\", \"Province Name\": \"Nova Scotia\", \"ID\": \"265\" },\n",
        "  { \"City Name\": \"Halifax\", \"Province Name\": \"Nova Scotia\", \"ID\": \"463\" },\n",
        "  { \"City Name\": \"Sydney\", \"Province Name\": \"Nova Scotia\", \"ID\": \"391\" },\n",
        "  { \"City Name\": \"Inuvik\", \"Province Name\": \"Northwest Territories\", \"ID\": \"253\" },\n",
        "  { \"City Name\": \"Yellowknife\", \"Province Name\": \"Northwest Territories\", \"ID\": \"468\" },\n",
        "  { \"City Name\": \"Hay River\", \"Province Name\": \"Northwest Territories\", \"ID\": \"251\" }\n",
        "]\n",
        "\n",
        "def _extract_annual_mean_temperature():\n",
        "  variable = \"meantemp\"\n",
        "\n",
        "  for city in cities:\n",
        "    city_id = city[\"ID\"]\n",
        "    city_name = city[\"City Name\"]\n",
        "    province_name = city[\"Province Name\"]\n",
        "\n",
        "    annual_mean_temp = _download_climate_atlas_data(city_id, variable)\n",
        "\n",
        "    yield (\n",
        "      city_id,\n",
        "      city_name,\n",
        "      province_name,\n",
        "      annual_mean_temp\n",
        "    )\n",
        "\n",
        "def _load_annual_mean_temperature():\n",
        "  annual_mean_temperature = _extract_annual_mean_temperature()\n",
        "\n",
        "  new_dir_xlsx = f\"{path}/Data\"\n",
        "  pathlib.Path(new_dir_xlsx).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  writer = pd.ExcelWriter(f'{new_dir_xlsx}/Mean Temperature - Climate Atlas Of Canada.xlsx', engine='xlsxwriter')\n",
        "  workbook = writer.book\n",
        "\n",
        "  for (city_id,\n",
        "       city_name,\n",
        "       province_name,\n",
        "       annual_mean_temp) in _extract_annual_mean_temperature():\n",
        "\n",
        "    worksheet = workbook.add_worksheet(city_name)\n",
        "    writer.sheets[city_name] = worksheet\n",
        "    annual_mean_temp.to_excel(writer, sheet_name=city_name)\n",
        "\n",
        "  writer.close()\n",
        "\n",
        "_load_annual_mean_temperature()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OsrLin7yehOx"
      },
      "source": [
        "## Canadian Government Reports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcKJ0cfGeiKs"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NG5Ek7hcPVyY"
      },
      "source": [
        "# Annual Precipitation Pipeline"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UkKlsR_QWi7n"
      },
      "source": [
        "## Downloading Data Utilities"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1d8OcYihWi7q"
      },
      "source": [
        "### Climate Atlas Of Canada\n",
        "\n",
        "I'm not proud of this method... however, I find it as an easier temporary solution...\n",
        "\n",
        "Rather then download and query data from the PCIC, I will directly download data from the Climate Atlas of Canada.\n",
        "\n",
        "I don't like doing this. However, given the time constraints, I certaintly need to get this done ASAP.\n",
        "\n",
        "A major TODO is to use PCIC data to collect the following data. I don't think it's right to scrape data that someone else preprocessed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_1I_SYIWi7u"
      },
      "outputs": [],
      "source": [
        "def _download_climate_atlas_data(city_num: int, variable: str):\n",
        "  possible_values = {\"precip\", \"meantemp\"}\n",
        "  if not variable in possible_values:\n",
        "    raise ValueError(f\"Invalid `variable` value. Should be in {possible_values}\")\n",
        "  \n",
        "  url = f\"https://data.climateatlas.ca/csv/city_{city_num}/BCCAQv2/85/city_{city_num}_BCCAQv2_RCP85_annual_{variable}_ensemble.csv\"\n",
        "\n",
        "  if r.get(url).status_code == 404:\n",
        "    raise ValueError(\"Invalid `city_num` value.\")\n",
        "\n",
        "  # The first 7 lines of any Climate Atlas Data Sheet looks\n",
        "  # like the following (for example)\n",
        "  #\n",
        "  # 1 | Bias  correction  method:  BCCAQv2\n",
        "  # 2 | Model  name:  Ensemble\n",
        "  # 3 | RCP:  85\n",
        "  # 4 | Variable:  tasmax  and  tasmin\n",
        "  # 5 | Season:  annual\n",
        "  # 6 | 1950-01-01  to  2095-12-31\n",
        "  # 7 | city_445:  Average  value  Mean  Ensemble\n",
        "  #\n",
        "  # I will skip these lines in order to get the needed\n",
        "  # data\n",
        "  return pd.read_csv(url, skiprows=7)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RvBGuzVHWzJB"
      },
      "source": [
        "## Climate Atlas Of Canada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp5w7KytWz0J"
      },
      "outputs": [],
      "source": [
        "# TODO: Specify the ID as a part of the data from the Climate Atlas of Canada.\n",
        "# the rough part would be tediously renaming everything. But alas, it would\n",
        "# clarify the distinction between the various data sources.\n",
        "cities = [\n",
        "  { \"City Name\": \"Timmins\", \"Province Name\": \"Ontario\", \"ID\": \"430\" },\n",
        "  { \"City Name\": \"Ottawa\", \"Province Name\": \"Ontario\", \"ID\": \"459\" },\n",
        "  { \"City Name\": \"Toronto\", \"Province Name\": \"Ontario\", \"ID\": \"458\" },\n",
        "  { \"City Name\": \"Thunder Bay\", \"Province Name\": \"Ontario\", \"ID\": \"444\" },\n",
        "  { \"City Name\": \"Regina\", \"Province Name\": \"Saskatchewan\", \"ID\": \"457\" },\n",
        "  { \"City Name\": \"Saskatoon\", \"Province Name\": \"Saskatchewan\", \"ID\": \"445\" },\n",
        "  { \"City Name\": \"Thompson\", \"Province Name\": \"Manitoba\", \"ID\": \"343\" },\n",
        "  { \"City Name\": \"Brandon\", \"Province Name\": \"Manitoba\", \"ID\": \"430\" },\n",
        "  { \"City Name\": \"Winnipeg\", \"Province Name\": \"Manitoba\", \"ID\": \"465\" },\n",
        "  { \"City Name\": \"Prince George\", \"Province Name\": \"British Columbia\", \"ID\": \"443\" },\n",
        "  { \"City Name\": \"Kelowna\", \"Province Name\": \"British Columbia\", \"ID\": \"442\" },\n",
        "  { \"City Name\": \"Vancouver\", \"Province Name\": \"British Columbia\", \"ID\": \"455\" },\n",
        "  { \"City Name\": \"Grande Prairie\", \"Province Name\": \"Alberta\", \"ID\": \"436\" },\n",
        "  { \"City Name\": \"Edmonton\", \"Province Name\": \"Alberta\", \"ID\": \"466\" },\n",
        "  { \"City Name\": \"Fort McMurray\", \"Province Name\": \"Alberta\", \"ID\": \"437\" },\n",
        "  { \"City Name\": \"Calgary\", \"Province Name\": \"Alberta\", \"ID\": \"454\" },\n",
        "  { \"City Name\": \"Edmundston\", \"Province Name\": \"New Brunswick\", \"ID\": \"273\" },\n",
        "  { \"City Name\": \"Bathurst\", \"Province Name\": \"New Brunswick\", \"ID\": \"274\" },\n",
        "  { \"City Name\": \"Frecdricton\", \"Province Name\": \"New Brunswick\", \"ID\": \"461\" },\n",
        "  { \"City Name\": \"Moncton\", \"Province Name\": \"New Brunswick\", \"ID\": \"394\" },\n",
        "  { \"City Name\": \"Saint John\", \"Province Name\": \"New Brunswick\", \"ID\": \"393\" },\n",
        "  { \"City Name\": \"Labrador City\", \"Province Name\": \"NewfoundLand\", \"ID\": \"260\" },\n",
        "  { \"City Name\": \"Cornoerbrook\", \"Province Name\": \"NewfoundLand\", \"ID\": \"493\" },\n",
        "  { \"City Name\": \"St John\", \"Province Name\": \"NewfoundLand\", \"ID\": \"464\" },\n",
        "  { \"City Name\": \"Cambridge Bay\", \"Province Name\": \"Nunavut\", \"ID\": \"254\" },\n",
        "  { \"City Name\": \"Arviat\", \"Province Name\": \"Nunavut\", \"ID\": \"248\" },\n",
        "  { \"City Name\": \"Iqaluit\", \"Province Name\": \"Nunavut\", \"ID\": \"246\" },\n",
        "  { \"City Name\": \"Dawson\", \"Province Name\": \"Yukon\", \"ID\": \"58\" },\n",
        "  { \"City Name\": \"Whitehorse\", \"Province Name\": \"Yukon\", \"ID\": \"467\" },\n",
        "  { \"City Name\": \"Sept-iles\", \"Province Name\": \"Quebec\", \"ID\": \"303\" },\n",
        "  { \"City Name\": \"Val-d'Or\", \"Province Name\": \"Quebec\", \"ID\": \"297\" },\n",
        "  { \"City Name\": \"Inukjuak\", \"Province Name\": \"Quebec\", \"ID\": \"145\" },\n",
        "  { \"City Name\": \"Montreal\", \"Province Name\": \"Quebec\", \"ID\": \"450\" },\n",
        "  { \"City Name\": \"Quebec\", \"Province Name\": \"Quebec\", \"ID\": \"460\" },\n",
        "  { \"City Name\": \"Summerside\", \"Province Name\": \"PEI\", \"ID\": \"262\" },\n",
        "  { \"City Name\": \"Charlottetown\", \"Province Name\": \"PEI\", \"ID\": \"462\" },\n",
        "  { \"City Name\": \"Truro\", \"Province Name\": \"Nova Scotia\", \"ID\": \"265\" },\n",
        "  { \"City Name\": \"Halifax\", \"Province Name\": \"Nova Scotia\", \"ID\": \"463\" },\n",
        "  { \"City Name\": \"Sydney\", \"Province Name\": \"Nova Scotia\", \"ID\": \"391\" },\n",
        "  { \"City Name\": \"Inuvik\", \"Province Name\": \"Northwest Territories\", \"ID\": \"253\" },\n",
        "  { \"City Name\": \"Yellowknife\", \"Province Name\": \"Northwest Territories\", \"ID\": \"468\" },\n",
        "  { \"City Name\": \"Hay River\", \"Province Name\": \"Northwest Territories\", \"ID\": \"251\" }\n",
        "]\n",
        "\n",
        "def _extract_annual_precipitation():\n",
        "  variable = \"precip\"\n",
        "\n",
        "  for city in cities:\n",
        "    city_id = city[\"ID\"]\n",
        "    city_name = city[\"City Name\"]\n",
        "    province_name = city[\"Province Name\"]\n",
        "\n",
        "    annual_precipitation = _download_climate_atlas_data(city_id, variable)\n",
        "\n",
        "    yield (\n",
        "      city_id,\n",
        "      city_name,\n",
        "      province_name,\n",
        "      annual_precipitation\n",
        "    )\n",
        "\n",
        "def _load_annual_precipitation():\n",
        "  annual_precipitation = _extract_annual_precipitation()\n",
        "\n",
        "  new_dir_xlsx = f\"{path}/Data\"\n",
        "  pathlib.Path(new_dir_xlsx).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  writer = pd.ExcelWriter(f'{new_dir_xlsx}/Annual Precipitation Pipeline - Climate Atlas Of Canada.xlsx', engine='xlsxwriter')\n",
        "  workbook = writer.book\n",
        "\n",
        "  for (city_id,\n",
        "       city_name,\n",
        "       province_name,\n",
        "       annual_precipitation) in _extract_annual_precipitation():\n",
        "\n",
        "    worksheet = workbook.add_worksheet(city_name)\n",
        "    writer.sheets[city_name] = worksheet\n",
        "    annual_precipitation.to_excel(writer, sheet_name=city_name)\n",
        "\n",
        "  writer.close()\n",
        "\n",
        "_load_annual_precipitation()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sSTwiwCoberY"
      },
      "source": [
        "# Greenhouse Gas Emissions Pipeline"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LAoMuWMWWkOy"
      },
      "source": [
        "## Statistics Canada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAfoWpDXWmZM"
      },
      "outputs": [],
      "source": [
        "def _extract_greenhouse_gas_emissions():\n",
        "  url = \"https://www150.statcan.gc.ca/n1/en/tbl/csv/38100097-eng.zip\"\n",
        "\n",
        "  req = r.get(url, stream=True)\n",
        "  req_stream = BytesIO(req.content)\n",
        "\n",
        "  zipped_dataset = ZipFile(req_stream)\n",
        "\n",
        "  greenhouse_gas_emissions = pd.read_csv(zipped_dataset.open('38100097.csv'))\n",
        "\n",
        "  return greenhouse_gas_emissions\n",
        "\n",
        "def _transform_greenhouse_gas_emissions():\n",
        "  greenhouse_gas_emissions = _extract_greenhouse_gas_emissions()\n",
        "  greenhouse_gas_emissions = greenhouse_gas_emissions[[\"REF_DATE\", \"GEO\", \"VALUE\"]]\n",
        "\n",
        "  greenhouse_gas_emissions[\"VALUE\"] = greenhouse_gas_emissions[\"VALUE\"].fillna(0.0)\n",
        "\n",
        "  return greenhouse_gas_emissions\n",
        "\n",
        "def _load_greenhouse_gas_emissions():\n",
        "  greenhouse_gas_emissions = _transform_greenhouse_gas_emissions()\n",
        "\n",
        "  new_dir_xlsx = f\"{path}/Data\"\n",
        "  pathlib.Path(new_dir_xlsx).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  writer = pd.ExcelWriter(f'{new_dir_xlsx}/Greenhouse Gas Emissions - Statistics Canada.xlsx', engine='xlsxwriter')\n",
        "  workbook = writer.book\n",
        "\n",
        "  for province_name, province_df in greenhouse_gas_emissions.groupby(\"GEO\"):\n",
        "    worksheet = workbook.add_worksheet(province_name)\n",
        "    writer.sheets[province_name] = worksheet\n",
        "    province_df.to_excel(writer, sheet_name=province_name)\n",
        "\n",
        "  writer.close()\n",
        "\n",
        "_load_greenhouse_gas_emissions()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "i3ZTmnCsnAvM"
      },
      "source": [
        "# Generating Mockups\n",
        "\n",
        "These set of utilities generates mockups from the ingested data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "u5OlQykNOMyh"
      },
      "source": [
        "## Empty Mockups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "O6ISG2pyq9Qa",
        "outputId": "070f0e54-f5a2-4eac-fa5f-e32bd6480fc2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-884a383d658b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Remove the 'Mocks' directory if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path}/Mocks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Get all XLSX files recursively under the 'Data' directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'shutil' is not defined"
          ]
        }
      ],
      "source": [
        "# Config\n",
        "lines_of_data = 0\n",
        "\n",
        "# Remove the 'Mocks' directory if it exists\n",
        "shutil.rmtree(f\"{path}/Mocks\", ignore_errors=True)\n",
        "\n",
        "# Get all XLSX files recursively under the 'Data' directory\n",
        "excel_files = glob.glob(f\"{path}/Data/**/*.xlsx\", recursive=True)\n",
        "\n",
        "# Remove the 'Mocks' directory if it exists\n",
        "shutil.rmtree(f\"{path}/Mocks\", ignore_errors=True)\n",
        "\n",
        "# Get all XLSX files recursively under the 'Data' directory\n",
        "excel_files = glob.glob(f\"{path}/Data/**/*.xlsx\", recursive=True)\n",
        "\n",
        "for excel_file in excel_files:\n",
        "  mock_file = excel_file \\\n",
        "    .replace(\"/WIP Thanussian/Data\", \"/WIP Thanussian/Mocks\")\n",
        "\n",
        "  pathlib.Path(mock_file) \\\n",
        "    .parent \\\n",
        "    .mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "  dfs = pd.read_excel(excel_file, sheet_name=None)\n",
        "\n",
        "  writer = pd.ExcelWriter(mock_file, engine='xlsxwriter')\n",
        "  workbook = writer.book\n",
        "\n",
        "  for sheet_name in dfs:\n",
        "    worksheet = workbook.add_worksheet(sheet_name)\n",
        "    writer.sheets[sheet_name] = worksheet\n",
        "\n",
        "    if lines_of_data == 0:\n",
        "      df_columns = list(dfs[sheet_name].iloc[0:0])\n",
        "      df_columns[0] = \"\"\n",
        "      df = pd.DataFrame(columns=df_columns, index=range(3))\n",
        "\n",
        "    elif lines_of_data > 0:\n",
        "      df = dfs[sheet_name].head(lines_of_data)\n",
        "\n",
        "    df.to_excel(writer, sheet_name=sheet_name)\n",
        "\n",
        "  writer.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
